{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840b71da",
   "metadata": {},
   "source": [
    "# Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c15a87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavisanthoshkumar/Library/CloudStorage/OneDrive-IllinoisInstituteofTechnology/RAG_krishnaNayak/RAG/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "import PyPDF2\n",
    "import certifi\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "from uuid import uuid4\n",
    "\n",
    "# Decorator packages\n",
    "from IPython.display import display, Markdown\n",
    "from tqdm import tqdm\n",
    "\n",
    "# langchain core packages\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import (PromptTemplate, \n",
    "                                    ChatPromptTemplate)\n",
    "\n",
    "\n",
    "# langchain Text \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# langchain\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.load import loads, dumps \n",
    "\n",
    "# Embeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Vector Database \n",
    "from pymongo import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c6b42",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319cedf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_pdf_filepath = \"../data/Harry Potter - Book 1 - The Sorcerers Stone.pdf\"\n",
    "\n",
    "with open(book_pdf_filepath, \"rb\") as pdf_file:\n",
    "    data = PyPDF2.PdfReader(pdf_file)\n",
    "    full_text = \" \".join([page.extract_text() for page in data.pages])\n",
    "\n",
    "full_text = full_text.replace(\"\\t\", \" \")\n",
    "full_text_doc = Document(\n",
    "    page_content = full_text, \n",
    "    metadata = {\"source\":\"github\", \"topic\":\"Harrypotter - Book\", \"chapter\":\"all_topics\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e70170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== SUCCESS LOAD: LANGCHAIN SERIALIZED OBJECT -> CHAPTERS ====\n",
      "==== SUCCESS LOAD: LANGCHAIN SERIALIZED OBJECT -> CHAPTER SUMMARIES ====\n",
      "==== SUCCESS : LANGCHAIN SERIALIZED OBJECT -> QUOTE DOCUMENTS ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/pgtp_zhj7n3717r3m0prtkdh0000gn/T/ipykernel_87175/1248285111.py:4: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  chapters = loads(serialized_chapter)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"../data/ingestion_processed/serialized_chapter.json\", \"r\") as f:\n",
    "        serialized_chapter = f.read()\n",
    "    chapters = loads(serialized_chapter)\n",
    "    print(\"==== SUCCESS LOAD: LANGCHAIN SERIALIZED OBJECT -> CHAPTERS ====\")        \n",
    "except:\n",
    "    print(\"==== FAILURE LOAD: LANGCHAIN SERIALIZED OBJECT -> CHAPTERS ====\")\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(\"../data/ingestion_processed/serialized_chapter_summaries.json\", \"r\") as f:\n",
    "        serialized_chapter_summaries = f.read()\n",
    "    chapter_summaries = loads(serialized_chapter_summaries)\n",
    "    print(\"==== SUCCESS LOAD: LANGCHAIN SERIALIZED OBJECT -> CHAPTER SUMMARIES ====\")        \n",
    "except:\n",
    "    print(\"==== FAILURE LOAD: LANGCHAIN SERIALIZED OBJECT -> CHAPTER SUMMARIES ====\")\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(\"../data/ingestion_processed/serialized_quotes_documents.json\", \"r\") as f:\n",
    "        serialized_quotes_documents = f.read()\n",
    "    quotes_documents = loads(serialized_quotes_documents)\n",
    "    print(\"==== SUCCESS : LANGCHAIN SERIALIZED OBJECT -> QUOTE DOCUMENTS ====\")        \n",
    "except:\n",
    "    print(\"==== FAILURE: LANGCHAIN SERIALIZED OBJECT -> QUOTE DOCUMENTS ====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0989065",
   "metadata": {},
   "source": [
    "# 3. Get Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38093e51",
   "metadata": {},
   "source": [
    "#### Initialize MongoDB Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f5b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGODB_ATLAS_CLUSTER_URI = getpass.getpass(\"MongoDB Atlas Cluster URI:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dcb5fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient(MONGODB_ATLAS_CLUSTER_URI, \n",
    "                     server_api=ServerApi('1'), \n",
    "                     tlsCAFile=certifi.where())\n",
    "DB_NAME = \"harry_potter_db\"\n",
    "DB_COLLECTION_NAME = \"harry_potter_collection\"\n",
    "DB_SEARCH_INDEX_NAME = \"langchain-test-index-vectorstore_1\"\n",
    "MONGODB_COLLECTION = client[DB_NAME][DB_COLLECTION_NAME]\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cdea0a",
   "metadata": {},
   "source": [
    "#### 1. Creating Retriever for Chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f04a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateRetriever:\n",
    "    \"\"\"\n",
    "        Function : Generate Retreiver \n",
    "\n",
    "        Params :\n",
    "            chunk_size : RecursiveTextSplitter parameter\n",
    "            chunk_overlap : RecursiveTextSplitter parameter\n",
    "            db_name : MongoDB DB Name\n",
    "            collection_name : MongoDB Collection Name\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chunk_size: int, chunk_overlap: int, db_name: str, db_search_index_name:str, \n",
    "                collection_name:str, model_name:str, documents: Document, search_type:str, top_k_documents:int):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.db_name = db_name\n",
    "        self.collection_name = collection_name \n",
    "        self.model_name = model_name\n",
    "        self.db_search_index_name =  db_search_index_name\n",
    "        self.search_type = search_type \n",
    "        self.top_k_documents = top_k_documents\n",
    "        self.documents = documents\n",
    "\n",
    "    def getMongoDBclient(self, embeddings):\n",
    "        # Collection Name and Database Name\n",
    "        MONGODB_COLLECTION = client[self.db_name][self.collection_name]\n",
    "        try:\n",
    "            # Store embedding in the vector store\n",
    "            self.vector_store = MongoDBAtlasVectorSearch(\n",
    "                collection = MONGODB_COLLECTION, \n",
    "                embedding = embeddings, \n",
    "                index_name = self.db_search_index_name,\n",
    "                relevance_score_fn = \"cosine\",\n",
    "            )\n",
    "            self.vector_store.create_vector_search_index(dimensions = 384)\n",
    "            print(\"===== Success : Store Embeddings in Vector Store =====\")\n",
    "        except Exception as e:\n",
    "            print(\"===== Failure : Store Embeddings in Vector Store =====\", e)\n",
    "\n",
    "        return self.vector_store \n",
    "\n",
    "    def getRecursiveCharacterTextSplitter(self):\n",
    "        # Define the text splitter \n",
    "        try:\n",
    "            self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size = self.chunk_size, \n",
    "                chunk_overlap = self.chunk_overlap, \n",
    "                length_function = len\n",
    "            )\n",
    "            print(\"===== Success : Load Recursive Character Text Splitter =====\")\n",
    "        except Exception as e:\n",
    "            print(\"===== Failure : Load Recursive Character Text Splitter =====\", e)\n",
    "\n",
    "    \n",
    "    def getEmbeddingsModel(self):\n",
    "        try:\n",
    "            model_kwargs = {\"device\":\"mps\"}\n",
    "            self.embedding_model = HuggingFaceEmbeddings(model_name = self.model_name,\n",
    "                                             model_kwargs = model_kwargs)\n",
    "            self.embedding_model.embed_query(text = \"Are you working perfectly fine?\")\n",
    "            print(\"==== Success : Initiate Embedding Model =====\")    \n",
    "        except Exception as e:\n",
    "            print(\"===== Failure : Initiate Embedding Model=====\", e)\n",
    "\n",
    "        \n",
    "    def generateEmbeddings(self):\n",
    "\n",
    "        # load embedding model\n",
    "        self.getEmbeddingsModel()\n",
    "\n",
    "        # load recursive character text splitter \n",
    "        self.getRecursiveCharacterTextSplitter()\n",
    "\n",
    "        # Split the documents \n",
    "        documents = self.text_splitter.split_documents(self.documents)\n",
    "\n",
    "        # Generate Embeddings and Save the documents in MongoDB Vector Database\n",
    "        self.vector_store = self.getMongoDBclient(embeddings=self.embedding_model)\n",
    "        uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "        self.vector_store.add_documents(documents=documents, ids = uuids)\n",
    "\n",
    "        # Convert Vector Store as Retriever\n",
    "        retriever = self.vector_store.as_retriever(search_type = self.search_type, \n",
    "                                                   search_kwargs = {\"k\": self.top_k_documents})\n",
    "\n",
    "        return retriever\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d7debf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/pgtp_zhj7n3717r3m0prtkdh0000gn/T/ipykernel_87175/1187754894.py:59: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embedding_model = HuggingFaceEmbeddings(model_name = self.model_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Success : Initiate Embedding Model =====\n",
      "===== Success : Load Recursive Character Text Splitter =====\n",
      "===== Success : Store Embeddings in Vector Store =====\n"
     ]
    }
   ],
   "source": [
    "chapter_retriever_model = GenerateRetriever(\n",
    "    chunk_size = 1000, \n",
    "    chunk_overlap = 100, \n",
    "    db_name = \"HarryPotter_db\", \n",
    "    db_search_index_name = \"chapterIndex_1\", \n",
    "    collection_name = \"HarryPotterCollection_Chapter\", \n",
    "    model_name = \"all-MiniLM-L6-v2\", \n",
    "    search_type=\"similarity\", \n",
    "    top_k_documents = 5,\n",
    "    documents= chapters\n",
    ")\n",
    "chapter_retriever = chapter_retriever_model.generateEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816a0e1a",
   "metadata": {},
   "source": [
    "#### 2. Creating Retriever for Chapter Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df4f321b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Success : Initiate Embedding Model =====\n",
      "===== Success : Load Recursive Character Text Splitter =====\n",
      "===== Success : Store Embeddings in Vector Store =====\n"
     ]
    }
   ],
   "source": [
    "chapter_summaries_retriever_model = GenerateRetriever(\n",
    "    chunk_size = 1000, \n",
    "    chunk_overlap = 100, \n",
    "    db_name = \"HarryPotter_db\", \n",
    "    db_search_index_name = \"HarryPotterSearch_ChapterSummariesIndex\", \n",
    "    collection_name = \"HarryPotterCollection_ChapterSummaries\", \n",
    "    model_name = \"all-MiniLM-L6-v2\", \n",
    "    search_type=\"similarity\", \n",
    "    top_k_documents = 5,\n",
    "    documents= chapter_summaries\n",
    ")\n",
    "chapter_summaries_retriever = chapter_summaries_retriever_model.generateEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b08e59",
   "metadata": {},
   "source": [
    "#### 3. Creating Retriever for Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bb98a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Success : Initiate Embedding Model =====\n",
      "===== Success : Load Recursive Character Text Splitter =====\n",
      "===== Failure : Store Embeddings in Vector Store ===== The maximum number of FTS indexes has been reached for this instance size., full error: {'ok': 0.0, 'errmsg': 'The maximum number of FTS indexes has been reached for this instance size.', 'code': 20, 'codeName': 'IllegalOperation', '$clusterTime': {'clusterTime': Timestamp(1759122390, 38), 'signature': {'hash': b\"\\xe7\\x828\\xbf\\x07\\x13\\xbd\\x03\\x98\\xff\\xbcm'\\x8a\\xd9!\\x19\\x9bd\\xed\", 'keyId': 7495132185410666498}}, 'operationTime': Timestamp(1759122390, 38)}\n"
     ]
    }
   ],
   "source": [
    "quotes_retriever_model = GenerateRetriever(\n",
    "    chunk_size = 1000, \n",
    "    chunk_overlap = 100, \n",
    "    db_name = \"HarryPotter_db\", \n",
    "    db_search_index_name = \"HarryPotterSearch_QuotesIndex\", \n",
    "    collection_name = \"HarryPotterCollection_Quotes\", \n",
    "    model_name = \"all-MiniLM-L6-v2\", \n",
    "    search_type=\"similarity\", \n",
    "    top_k_documents = 5,\n",
    "    documents= quotes_documents\n",
    ")\n",
    "quotes_retriever = quotes_retriever_model.generateEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c502c1",
   "metadata": {},
   "source": [
    "#### 4. Creating Retriever for Full Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4032f708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Success : Initiate Embedding Model =====\n",
      "===== Success : Load Recursive Character Text Splitter =====\n",
      "===== Success : Store Embeddings in Vector Store =====\n"
     ]
    }
   ],
   "source": [
    "fulltext_retriever_model = GenerateRetriever(\n",
    "    chunk_size = 1000, \n",
    "    chunk_overlap = 100, \n",
    "    db_name = \"HarryPotter_db\", \n",
    "    db_search_index_name = \"HarryPotterSearch_FullTextIndex\", \n",
    "    collection_name = \"HarryPotterCollection_FullText\", \n",
    "    model_name = \"all-MiniLM-L6-v2\", \n",
    "    search_type=\"similarity\", \n",
    "    top_k_documents = 5,\n",
    "    documents= [full_text_doc]\n",
    ")\n",
    "fulltext_retriever = fulltext_retriever_model.generateEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccee086",
   "metadata": {},
   "source": [
    "#### 4. Input the Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0ade649",
   "metadata": {},
   "outputs": [],
   "source": [
    "query  = 'In the first chapter of \"Harry Potter and the Sorcerer\\'s Stone,\" we are introduced to the Dursley family, who live on Privet Drive and consider themselves to be perfectly normal and ordinary.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc253f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "HP 1 - Harry Potter and the\n",
       "Sorcerer's Stone\n",
       "Harry Potter and the Sorcerer's Stone\n",
       " \n",
       " \n",
       "Harry Potter\n",
       "&\n",
       "The Sorcerer’s Stone\n",
       " \n",
       " \n",
       "by \n",
       "J.K. Rowling\n",
       " \n",
       " \n",
       " \n",
       " \n",
       "  HP 1 - Harry Potter and the\n",
       "Sorcerer's Stone CHAPTER ONE\n",
       " \n",
       "THE BOY WHO LIVED\n",
       " \n",
       "      \n",
       "M \n",
       "r. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
       "that they were perfectly normal, thank you very much. They were the last people\n",
       "you’d expect to be involved in anything strange or mysterious, because they just\n",
       "didn’t hold with such nonsense.\n",
       "      Mr. Dursley was the director of a firm called Grunnings, which made\n",
       "drills. He was a big, beefy man with hardly any neck, although he did have a\n",
       "very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the\n",
       "usual amount of neck, which came in very useful as she spent so much of her\n",
       "time craning over garden fences, spying on the neighbors. The Dursleys had a\n",
       "small son called Dudley and in their opinion there was no finer boy anywhere."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(fulltext_retriever.invoke(query)[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2df5799a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In the first chapter of \"Harry Potter and the Sorcerer's Stone,\" we are introduced to the Dursley family, who live on Privet Drive and consider themselves to be perfectly normal and ordinary. Mr. Dursley works at a drill company and Mrs. Dursley is preoccupied with spying on their neighbors. They have a son named Dudley whom they dote on. The Dursleys have a deep secret that they fear will be discovered, concerning Mrs. Dursley's sister, Lily Potter, and her family.\n",
       "\n",
       "One morning, as Mr. Dursley goes about his usual routine, he notices strange occurrences around town, such as people in cloaks and oddly dressed individuals whispering excitedly. He becomes increasingly agitated and worried, especially when he overhears discussions about the Potters. He dismisses these concerns as paranoia and tries to focus on work."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(chapter_summaries_retriever.invoke(query)[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "549ffa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "CHAPTER\tONE\n",
       "\t\n",
       "THE\tBOY\tWHO\tLIVED\n",
       "\t\n",
       "\t\t\t\t\t\t\n",
       "M\t\n",
       "r.\tand\tMrs.\tDursley,\tof\tnumber\tfour,\tPrivet\tDrive,\twere\tproud\tto\tsay\n",
       "that\tthey\twere\tperfectly\tnormal,\tthank\tyou\tvery\tmuch.\tThey\twere\tthe\tlast\tpeople\n",
       "you’d\texpect\tto\tbe\tinvolved\tin\tanything\tstrange\tor\tmysterious,\tbecause\tthey\tjust\n",
       "didn’t\thold\twith\tsuch\tnonsense.\n",
       "\t\t\t\t\t\tMr.\tDursley\twas\tthe\tdirector\tof\ta\tfirm\tcalled\tGrunnings,\twhich\tmade\n",
       "drills.\tHe\twas\ta\tbig,\tbeefy\tman\twith\thardly\tany\tneck,\talthough\the\tdid\thave\ta\n",
       "very\tlarge\tmustache.\tMrs.\tDursley\twas\tthin\tand\tblonde\tand\thad\tnearly\ttwice\tthe\n",
       "usual\tamount\tof\tneck,\twhich\tcame\tin\tvery\tuseful\tas\tshe\tspent\tso\tmuch\tof\ther\n",
       "time\tcraning\tover\tgarden\tfences,\tspying\ton\tthe\tneighbors.\tThe\tDursleys\thad\ta\n",
       "small\tson\tcalled\tDudley\tand\tin\ttheir\topinion\tthere\twas\tno\tfiner\tboy\tanywhere.\n",
       "\t\t\t\t\t\tThe\tDursleys\thad\teverything\tthey\twanted,\tbut\tthey\talso\thad\ta\tsecret,\tand\n",
       "their\tgreatest\tfear\twas\tthat\tsomebody\twould\tdiscover\tit.\tThey\tdidn’t\tthink\tthey\n",
       "could\tbear\tit\tif\tanyone\tfound\tout\tabout\tthe\tPotters.\tMrs.\tPotter\twas\tMrs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(chapter_retriever.invoke(query)[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d88b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
